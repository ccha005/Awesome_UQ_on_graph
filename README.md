# Awesome_UQ_on_graph
This repository contains research papers and surveys that are relevant to **Uncertainty Quantification**, especially those on **Graphs**.

## Research Papers

### UQ on Machine Learning

**Bayesian Method**

[B1]Variational Inference: A Review for Statisticians [JASA 2017](https://www.tandfonline.com/doi/pdf/10.1080/01621459.2017.1285773)

[B2]Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning [ICML 2016](https://proceedings.mlr.press/v48/gal16.html)

[B3]B-PINNs Bayesian physics-informed neural networks for forward and inverse PDE problems with noisy data [JCP 2020](https://arxiv.org/abs/2003.06097)

[B4]Stochastic Variational Inference[JMLR 2013](https://jmlr.org/papers/volume14/hoffman13a/hoffman13a.pdf)

[B5]Deep Bayesian Active Learning with Image Data [ICML 2017](https://arxiv.org/abs/1703.02910)

[B6]MCMC using Hamiltonian dynamics[Handbook of markov chain monte carlo](https://arxiv.org/abs/1206.1901)

[B7]Probabilistic backpropagation for scalable learning of Bayesian neural networks[ICML 2015](https://proceedings.mlr.press/v37/hernandez-lobatoc15.html)

[B8]A Scalable Laplace Approximation for Neural Networks[ICLR 2018](https://openreview.net/forum?id=Skdvd2xAZ)

[B9]Weight Uncertainty in Neural Network[ICML 2015](https://proceedings.mlr.press/v37/blundell15.html)

[B10]The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo[JMLR 2014](https://jmlr.org/papers/volume15/hoffman14a/hoffman14a.pdf)

**Conformal Prediction**

[CP1]Conformalized Quantile Regression [NeurIPS 2019](https://proceedings.neurips.cc/paper_files/paper/2019/hash/5103c3584b063c431bd1268e9b5e76fb-Abstract.html)

[CP2]Conformal Prediction Under Covariate Shift [NeurIPS 2019](https://proceedings.neurips.cc/paper/2019/file/8fb21ee7a2207526da55a679f0332de2-Paper.pdf)

[CP3]Adaptive Conformal Inference Under Distribution Shift [NeurIPS 2021](https://proceedings.neurips.cc/paper/2021/hash/0d441de75945e5acbc865406fc9a2559-Abstract.html)

[CP4]Localized conformal prediction: a generalized inference framework for conformal prediction [Biometrika 2023](https://academic.oup.com/biomet/article/110/1/33/6647831?login=false)

[CP5]Conformal Prediction with Missing Values [ICML 2023](https://proceedings.mlr.press/v202/zaffran23a.html)

[CP6]Split Localized Conformal Prediction [Arxiv](https://arxiv.org/pdf/2206.13092.pdf)

[CP7]A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification [Foundations and TrendsÂ® in Machine Learning](https://arxiv.org/abs/2107.07511)

[CP8] Multi-Split Conformal Prediction [Statistics & Probability Letters 2022](https://www.sciencedirect.com/science/article/abs/pii/S0167715222000177#:~:text=The%20multi%20split%20approach%20consists,frequency%20greater%20than%20a%20threshold.)

[CP9] Stable Conformal Prediction Sets [ICML 2022](https://icml.cc/virtual/2022/oral/16842)

[CP10] Cross-conformal predictive distributions[ICML 2018](https://proceedings.mlr.press/v91/vovk18a.html?ref=https://githubhelp.com)

[CP11] Algorithmic Learning in a Random World[Book 2005](https://link.springer.com/book/10.1007/978-3-031-06649-8)

[CP12] Classification with valid and adaptive coverage [NeurIPS 2020](https://proceedings.neurips.cc/paper/2020/file/244edd7e85dc81602b7615cd705545f5-Paper.pdf)

[CP13] Uncertainty sets for image classifiers using conformal prediction [Arxiv 2020](https://arxiv.org/abs/2009.14193)

[CP14] Conformal prediction interval for dynamic time-series [ICML 2021](https://proceedings.mlr.press/v139/xu21h/xu21h.pdf)

[CP15] Conformal prediction beyond exchangeability [Ann. Statist. 2O23](https://projecteuclid.org/journals/annals-of-statistics/volume-51/issue-2/Conformal-prediction-beyond-exchangeability/10.1214/23-AOS2276.full)

[CP16] A comparison of some conformal quantile regression methods [Wiley Online Library](https://onlinelibrary.wiley.com/doi/pdf/10.1002/sta4.261)

[CP17] Cross-conformal predictors [AMAI](https://link.springer.com/content/pdf/10.1007/s10472-013-9368-4.pdf)

[CP18] Predictive inference with the jackknife+ [Ann. Statist. 2021](https://projecteuclid.org/journals/annals-of-statistics/volume-49/issue-1/Predictive-inference-with-the-jackknife/10.1214/20-AOS1965.full)

[CP19]  Bayes-optimal prediction with frequentist coverage control [Bernoulli 2023](https://projecteuclid.org/journals/bernoulli/volume-29/issue-2/Bayes-optimal-prediction-with-frequentist-coverage-control/10.3150/22-BEJ1484.full)

[CP20] Learning optimal conformal classifiers [Arxiv](https://arxiv.org/abs/2110.09192)

[CP21] Knowing what you know: valid and validated confidence sets in multiclass and multilabel prediction [JMLR2021](https://www.jmlr.org/papers/v22/20-753.html)

[CP22] Improving conditional coverage via orthogonal quantile regression [NIPS2021](https://proceedings.neurips.cc/paper_files/paper/2021/hash/1006ff12c465532f8c574aeaa4461b16-Abstract.html)

**Calibration**

[CA1] Obtaining calibrated probability estimates from decision trees and naive Bayesian classifiers [ICML2021](https://cseweb.ucsd.edu/~elkan/calibrated.pdf)

[CA2]Transforming classifier scores into accurate multiclass probability estimates [KDD 2002](https://dl.acm.org/doi/abs/10.1145/775047.775151?casa_token=paJquWBAGcEAAAAA:Rom9rJ8vuvp64B3vQNWGX5ObNCV_Fu40LBVUUVA7rS5HtMkjhoPpzNGjLHa86EqWkAV9EmrBaqf1Jw)

[CA3]Accurate uncertainties for deep learning using calibrated regression[ICML 2018](https://proceedings.mlr.press/v80/kuleshov18a.html)

[CA4]Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods [Advances in large margin classifiers 1999](https://www.researchgate.net/profile/John-Platt-2/publication/2594015_Probabilistic_Outputs_for_Support_Vector_Machines_and_Comparisons_to_Regularized_Likelihood_Methods/links/004635154cff5262d6000000/Probabilistic-Outputs-for-Support-Vector-Machines-and-Comparisons-to-Regularized-Likelihood-Methods.pdf)

[CA5]When does label smoothing help? [NIPS2019](https://proceedings.neurips.cc/paper_files/paper/2019/hash/f1748d6b0fd9d439f71450117eba2725-Abstract.html)

[CA6]Focal loss for dense object detection [ICCV 2017](https://openaccess.thecvf.com/content_iccv_2017/html/Lin_Focal_Loss_for_ICCV_2017_paper.html)

[CA7]Calibrating deep neural networks using focal loss [NIPS 2020](https://proceedings.neurips.cc/paper/2020/hash/aeb7b30ef1d024a76f21a1d40e30c302-Abstract.html)

[CA8]Obtaining well-calibrated probabilities using Bayesian binning [AAAI 2015](https://ojs.aaai.org/index.php/AAAI/article/view/9602)

[CA9]Beyond temperature scaling: Obtaining well-calibrated multi-class probabilities with Dirichlet calibration. [NIPS 2019](https://proceedings.neurips.cc/paper/2019/hash/8ca01ea920679a0fe3728441494041b9-Abstract.html)

[CA10]A graph is more than its nodes: Towards structured uncertainty-aware learning on graphs [Arxiv 2022](https://arxiv.org/abs/2210.15575)

[CA11]Improving model calibration with accuracy versus uncertainty optimization [NIPS 2020](https://proceedings.neurips.cc/paper_files/paper/2020/hash/d3d9446802a44259755d38e6d163e820-Abstract.html)

**Other Methods**

[O1]Beyond Pinball Loss: Quantile Methods for Calibrated Uncertainty Quantification [NIPS 2021](https://openreview.net/forum?id=QbVza2PKM7T)


### UQ on Graph

**Graphical Model**

[P1]Model Uncertainty and Correctability for Directed Graphical Models [SIAM/ASA Journal on Uncertainty Quantification 2022](https://epubs.siam.org/doi/abs/10.1137/21M1434453)

[P2]Uncertainty Quantification for Markov Random Fields [SIAM/ASA Journal on Uncertainty Quantification 2021](https://epubs.siam.org/doi/abs/10.1137/20M1374614)

[P3]The Power of Certainty: A Dirichlet-Multinomial Model for Belief Propagation [SDM 2017](https://epubs.siam.org/doi/pdf/10.1137/1.9781611974973.17)

[P4]SocNL: Bayesian Label Propagation with Confidence [PAKDD 2015](https://link.springer.com/chapter/10.1007/978-3-319-18038-0_49)

**GNN**

[G1]Conformal Prediction Sets for Graph Neural Networks [ICML 2023](https://proceedings.mlr.press/v202/h-zargarbashi23a.html)

[G2]Distribution Free Prediction Sets for Node Classification [ICML 2023](https://proceedings.mlr.press/v202/clarkson23a.html)

[G3]Uncertainty Quantification over Graph with Conformalized Graph Neural Networks [NeurIPS 2023](https://arxiv.org/abs/2305.14535)

[G4]A General Framework for Quantifying Aleatoric and Epistemic Uncertainty in Graph Neural Networks [Neurocomputing 2023](https://arxiv.org/pdf/2205.09968.pdf) 

[G5]Predictive Uncertainty Quantification for Graph Neural Network Driven Relaxed Energy Calcul1ations [NeurIPS AI4Science Workshop 2023](https://openreview.net/forum?id=rdgB5BqWCw)

[G6]Uncertainty Quantification of Spatiotemporal Travel Demand with Probabilistic Graph Neural Networks [ArXiv 2023](https://arxiv.org/abs/2303.04040)

[G7]Uncertainty Quantification of Sparse Travel Demand Prediction with Spatial-Temporal Graph Neural Networks [SIGKDD 2022](https://dl.acm.org/doi/abs/10.1145/3534678.3539093)

[G8]JuryGCN: Quantifying Jackknife Uncertainty on Graph Convolutional Networks [KDD 2022](https://dl.acm.org/doi/pdf/10.1145/3534678.3539286)

[G9]Be Confident! Towards Trustworthy Graph Neural Networks via Confidence Calibration [NeurIPS 2021](https://proceedings.neurips.cc/paper/2021/hash/c7a9f13a6c0940277d46706c7ca32601-Abstract.html)

[G10]Graph posterior network: Bayesian predictive uncertainty for node classification [NeurIPS 2021](https://proceedings.neurips.cc/paper_files/paper/2021/file/95b431e51fc53692913da5263c214162-Paper.pdf)

[G11]High-Quality Prediction Intervals for Deep Learning- A Distribution-Free, Ensembled Approach [ICML 2018](https://proceedings.mlr.press/v80/pearce18a.html)

[G12]Uncertainty Quantification in Graph-Based Classification of High Dimensional Data [SIAM/ASA Journal on Uncertainty Quantification 2018](https://epubs.siam.org/doi/abs/10.1137/17M1134214)

[G13]Bayesian graph convolutional neural networks for semi-supervised
classification [AAAI 2019](https://ojs.aaai.org/index.php/AAAI/article/download/4531/4409)

[G14]Bayesian graph convolutional neural networks using node copying [ICML Workshop 2019](https://arxiv.org/pdf/1911.04965)

[G15]Non parametric graph learning for bayesian graph neural networks [UAI 2020](http://proceedings.mlr.press/v124/pal20a/pal20a.pdf)

[G16]Are graph neural networks miscalibrated? [Arxiv](https://arxiv.org/abs/1905.02296)

[G17]What Makes Graph Neural Networks Miscalibrated? [NIPS 2022](https://proceedings.neurips.cc/paper_files/paper/2022/hash/5975754c7650dfee0682e06e1fec0522-Abstract-Conference.html)

[G18]GCL: Graph calibration loss for trustworthy graph neural network [MM 2022](https://dl.acm.org/doi/abs/10.1145/3503161.3548423?casa_token=oLE-X0PMypAAAAAA:EcB27ENIY5OkXut9rLe_LocviSKEPoJtxPyS3fmqZ7RG3ayU1CTbvwpbT5XJeLpGmrHqyanUuK7wZg)

[G19]On calibration of graph neural networks for node classification [ICJNN 2022](https://ieeexplore.ieee.org/abstract/document/9892866?casa_token=8gacSN0Z8ZgAAAAA:CerSGnfSVX_nsRe4cGLqdUs6_azca6GyO1_TmcVX_cj3owsYYbtUa610H2yzMBqXsNJu6wDuYWCM)

[G20]Calibrate automated graph neural network via hyperparameter uncertainty[CIKM 2022](https://dl.acm.org/doi/abs/10.1145/3511808.3557556?casa_token=4GVPgq11RzAAAAAA:0R-Cn6wtL5wMwR0Hjzf_SLjjBHaw9RXcHgJfQMTRi5XsXF_raV2er86RL-AagzKEBVl01auGftS3sw)

[G21]Accurate and Scalable Estimation of Epistemic Uncertainty for Graph Neural Networks [ICLR 2024](https://arxiv.org/abs/2401.03350)

[G22]A multi-view confidence-calibrated framework for fair and stable graph representation learning [ICDM 2021](https://ieeexplore.ieee.org/abstract/document/9679093?casa_token=pNyFkDpFxKYAAAAA:APzIRm9B8tSczE7x-70OtnXxqRX2JL6Av10PM2WvYOYZILgptsE90-hZe1Y-2pXO2cgMo27tq888)

[G23]Link prediction based on graph neural network[NIPS 2018](https://proceedings.neurips.cc/paper/2018/hash/53f0d7c537d99b3824f0f99d62ea2428-Abstract.html)

[G24]In-n-Out: Calibrating Graph Neural Networks for Link Prediction[Arxiv 2024](https://arxiv.org/abs/2403.04605)

[G25]On Estimating Link Prediction Uncertainty Using Stochastic Centering[ICASSP 2024](https://cmsworkshops.com/ICASSP2024/view_paper.php?PaperNum=7277)
## Survey Papers

### UQ on Machine Learning

[S1]Uncertainty quantification in scientific machine learning- Methods, metrics, and comparisons [JCP 2023](https://www.sciencedirect.com/science/article/abs/pii/S0021999122009652)

[S2]A review of uncertainty quantification in deep learning Techniques, applications, and challenges [Information Fusion 2021](https://www.sciencedirect.com/science/article/pii/S1566253521001081)

[S3]Basic Framework and Main Methods of Uncertainty Quantification [MPE 2020](https://www.hindawi.com/journals/mpe/2020/6068203/)

[S4]Calibrating Uncertainty Models for Steering Angle Estimation [IEEE 2019](https://ieeexplore.ieee.org/document/8917207)

[S5]Hands-on Bayesian Neural Networks -- A Tutorial for Deep Learning Users [IEEE CIM 2022](https://arxiv.org/abs/2007.06823)

[S6]A view on model misspecification in uncertainty quantification [BNAIC 2022](https://arxiv.org/abs/2210.16938)


Uncertainty Quantification in Machine Learning for Engineering Design and Health Prognostics: A Tutorial [Mechanical Systems and Signal Processing 2015](https://www.sciencedirect.com/science/article/pii/S0888327023007045)

## Benchmark

