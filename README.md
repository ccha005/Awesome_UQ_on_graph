# Awesome_UQ_on_graph
This repository contains research papers and surveys that are relevant to **Uncertainty Quantification**, especially those on **Graphs**.

## Research Papers

### UQ on Machine Learning

**Uncertainty Source**
ID | Paper Titles | Venues | Years 
--- | :------ | :---:  | :---:
[S17](https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/f2217062e9a397a1dca429e7d70bc6ca-Abstract-round1.html) | Pervasive label errors in test sets destabilize machine learning benchmark | NeurIPS | 2024
[S16](https://arxiv.org/abs/2305.16703) | Sources of Uncertainty in Machine Learning–A Statisticians’ View | arXiv | 2023
[S15](https://www.sciencedirect.com/science/article/abs/pii/S0925231222014424) | A general framework for quantifying aleatoric and epistemic uncertainty in graph neural networks | Neurocomputing | 2023
[S14](https://journals.sagepub.com/doi/full/10.1177/01492063211006458) | Omitted variable bias: Examining management research with the impact threshold of a confounding variable (ITCV) | Journal of Management | 2022 
[S13](https://ieeexplore.ieee.org/abstract/document/9857056?casa_token=tavc4KHf2CMAAAAA:pwv3ZZI4yueJuO1iYo1O31Dgs1KK_2hgbfaqE-6bRTOz1GhxdKbe8hCGxWhU5MlwrDFFO3I9pZKh) | A Deeper Look into Aleatoric and Epistemic Uncertainty Disentanglement | CVPR Workshop | 2021
[S12](https://books.google.nl/books?hl=en&lr=&id=BemMDwAAQBAJ&oi=fnd&pg=PR11&dq=Statistical+analysis+with+missing+data.&ots=FCzV8XJ_1Y&sig=cQ7RDScEhtICr79wp3JsdKTxKJs&redir_esc=y#v=onepage&q=Statistical%20analysis%20with%20missing%20data.&f=false) | Statistical analysis with missing data | John Wiley & Sons | 2021
[S11](https://arxiv.org/abs/2102.08501) | Deup: Direct epistemic uncertainty prediction | arXiv | 2021
[S10](https://link.springer.com/article/10.1007/s10994-021-05946-3) | Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and methods | Machine Learning | 2021
[S9](https://arxiv.org/abs/2110.12122) | Quantifying epistemic uncertainty in deep learning | arXiv | 2021
[S8](https://www.econstor.eu/handle/10419/260381) | Omitted variable bias in machine-learned causal models | | 2021
[S7](https://academic.oup.com/jrsssb/article/82/1/39/7056023) | Making sense of sensitivity: Extending omitted variable bias | Stat. Methodol. | 2020
[S6](https://link.springer.com/chapter/10.1007/978-3-030-33778-0_7) | Epistemic uncertainty sampling | Discovery science | 2019
[S5](https://www.sciencedirect.com/science/article/pii/S1877050919318575) | Dealing with noise problem in machine learning data-sets: A systematic review | Procedia Computer Science | 2019
[S4](https://proceedings.neurips.cc/paper/2017/hash/2650d6089a6d640c5e85b2b88265dc2b-Abstract.html) | What uncertainties do we need in Bayesian deep learning for computer vision? | NeurIPS | 2017
[S3](https://www.sciencedirect.com/science/article/abs/pii/S0167473008000556) | Aleatory or epistemic? Does it matter? | Structural safety | 2009
[S2](https://books.google.nl/books?hl=en&lr=&id=ewqzOGDKYscC&oi=fnd&pg=PA1&dq=The+emergence+of+probability:+A+philosophical+study+of+early+ideas+about+probability,+induction,+and+statistical+inference&ots=5JmIwBClUa&sig=l7oD7aSfiZYUnxa4pEqWEypgjLU#v=onepage&q=The%20emergence%20of%20probability%3A%20A%20philosophical%20study%20of%20early%20ideas%20about%20probability%2C%20induction%2C%20and%20statistical%20inference&f=false) | The emergence of probability: A philosophical study of early ideas about probability, induction, and statistical inference | Cambridge University Press | 2006
[S1](https://www.sciencedirect.com/science/article/abs/pii/S0951832096000774) | Aleatory and epistemic uncertainty in probability elicitation with an example from hazardous waste management | Reliability Engineering & System Safety | 1996

**Bayesian Method**
ID | Paper Titles | Venues | Years 
--- | :------ | :---:  | :---:
[B10](https://arxiv.org/abs/2003.06097) | B-PINNs Bayesian physics-informed neural networks for forward and inverse PDE problems with noisy data | JCP | 2020
[B9](https://openreview.net/forum?id=Skdvd2xAZ) | A Scalable Laplace Approximation for Neural Networks | ICLR | 2018
[B8](https://arxiv.org/abs/1703.02910) | Deep Bayesian Active Learning with Image Data | ICML | 2017
[B7](https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1285773) | Variational Inference: A Review for Statisticians | JASA | 2017
[B6](https://proceedings.mlr.press/v48/gal16.html) | Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning | ICML | 2016
[B5](https://proceedings.mlr.press/v37/blundell15.html) | Weight Uncertainty in Neural Network | ICML | 2015
[B4](https://proceedings.mlr.press/v37/hernandez-lobatoc15.html) | Probabilistic backpropagation for scalable learning of Bayesian neural networks | ICML | 2015
[B3](https://www.jmlr.org/papers/v15/hoffman14a.html) | The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo | JMLR | 2014
[B2](https://jmlr.org/papers/v14/hoffman13a.html) | Stochastic Variational Inference | JMLR | 2013
[B1](https://arxiv.org/abs/1206.1901) | MCMC using Hamiltonian dynamics | | 2011

**Conformal Prediction**
ID | Paper Titles | Venues | Years 
--- | :------ | :---:  | :---:
[CP22](https://academic.oup.com/biomet/article/110/1/33/6647831) | Localized conformal prediction: a generalized inference framework for conformal prediction | Biometrika | 2023
[CP21](https://proceedings.mlr.press/v202/zaffran23a.html) | Conformal Prediction with Missing Values | ICML | 2023
[CP20](https://projecteuclid.org/journals/annals-of-statistics/volume-51/issue-2/Conformal-prediction-beyond-exchangeability/10.1214/23-AOS2276.full) | Conformal prediction beyond exchangeability | Ann. Statist. | 2O23
[CP19](https://arxiv.org/abs/2206.13092) | Split Localized Conformal Prediction | arXiv | 2023
[CP18](https://projecteuclid.org/journals/bernoulli/volume-29/issue-2/Bayes-optimal-prediction-with-frequentist-coverage-control/10.3150/22-BEJ1484.full) | Bayes-optimal prediction with frequentist coverage control | Bernoulli | 2023
[CP17](https://arxiv.org/abs/2110.09192) | Learning optimal conformal classifiers | ICLR | 2022
[CP16](https://icml.cc/virtual/2022/oral/16842) | Stable Conformal Prediction Sets | ICML | 2022
[CP15](https://arxiv.org/abs/2107.07511) | A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification | Foundations and Trends® in Machine Learning | 2022
[CP14](https://www.sciencedirect.com/science/article/abs/pii/S0167715222000177) | Multi-Split Conformal Prediction | Statistics & Probability Letters | 2022
[CP13](https://www.jmlr.org/papers/v22/20-753.html) | Knowing what you know: valid and validated confidence sets in multiclass and multilabel prediction | JMLR | 2021
[CP12](https://proceedings.mlr.press/v139/xu21h) | Conformal prediction interval for dynamic time-series | ICML | 2021
[CP11](https://proceedings.neurips.cc/paper/2021/hash/0d441de75945e5acbc865406fc9a2559-Abstract.html) | Adaptive Conformal Inference Under Distribution Shift | NeurIPS | 2021
[CP10](https://proceedings.neurips.cc/paper_files/paper/2021/hash/1006ff12c465532f8c574aeaa4461b16-Abstract.html) | Improving conditional coverage via orthogonal quantile regression | NeurIPS | 2021
[CP9](https://projecteuclid.org/journals/annals-of-statistics/volume-49/issue-1/Predictive-inference-with-the-jackknife/10.1214/20-AOS1965.full) | Predictive inference with the jackknife+ | Ann. Statist. | 2021
[CP8](https://arxiv.org/abs/2009.14193) | Uncertainty sets for image classifiers using conformal prediction | ICLR | 2021
[CP7](https://onlinelibrary.wiley.com/doi/abs/10.1002/sta4.261) | A comparison of some conformal quantile regression methods | Stat | 2020
[CP6](https://proceedings.neurips.cc/paper/2020/hash/244edd7e85dc81602b7615cd705545f5-Abstract.html) | Classification with valid and adaptive coverage | NeurIPS | 2020
[CP5](https://proceedings.neurips.cc/paper_files/paper/2019/hash/5103c3584b063c431bd1268e9b5e76fb-Abstract.html) | Conformalized Quantile Regression | NeurIPS | 2019
[CP4](https://proceedings.neurips.cc/paper/2019/hash/8fb21ee7a2207526da55a679f0332de2-Abstract.html) | Conformal Prediction Under Covariate Shift | NeurIPS | 2019
[CP3](https://proceedings.mlr.press/v91/vovk18a) | Cross-conformal predictive distributions | ICML | 2018
[CP2](https://link.springer.com/article/10.1007/s10472-013-9368-4) | Cross-conformal predictors | AMAI | 2015
[CP1](https://link.springer.com/book/10.1007/978-3-031-06649-8) | Algorithmic Learning in a Random World | Springer | 2005

**Calibration**
ID | Paper Titles | Venues | Years 
--- | :------ | :---:  | :---:
[CA12](https://openreview.net/forum?id=QbVza2PKM7T) | Beyond Pinball Loss: Quantile Methods for Calibrated Uncertainty Quantification | NeurIPS | 2021
[CA11](https://arxiv.org/abs/2210.15575) | A graph is more than its nodes: Towards structured uncertainty-aware learning on graphs | NeurIPS Workshop | 2022
[CA10](https://proceedings.neurips.cc/paper_files/paper/2020/hash/d3d9446802a44259755d38e6d163e820-Abstract.html) | Improving model calibration with accuracy versus uncertainty optimization | NeurIPS | 2020
[CA9](https://proceedings.neurips.cc/paper/2020/hash/aeb7b30ef1d024a76f21a1d40e30c302-Abstract.html) | Calibrating deep neural networks using focal loss | NeurIPS | 2020
[CA8](https://proceedings.neurips.cc/paper/2019/hash/8ca01ea920679a0fe3728441494041b9-Abstract.html) | Beyond temperature scaling: Obtaining well-calibrated multi-class probabilities with Dirichlet calibration | NeurIPS | 2019
[CA7](https://proceedings.neurips.cc/paper_files/paper/2019/hash/f1748d6b0fd9d439f71450117eba2725-Abstract.html) | When does label smoothing help? | NeurIPS | 2019
[CA6](https://proceedings.mlr.press/v80/kuleshov18a.html) | Accurate uncertainties for deep learning using calibrated regression | ICML | 2018
[CA5](https://openaccess.thecvf.com/content_iccv_2017/html/Lin_Focal_Loss_for_ICCV_2017_paper.html) | Focal loss for dense object detection | ICCV | 2017
[CA4](https://ojs.aaai.org/index.php/AAAI/article/view/9602) | Obtaining well-calibrated probabilities using Bayesian binning | AAAI | 2015
[CA3](https://dl.acm.org/doi/abs/10.1145/775047.775151) | Transforming classifier scores into accurate multiclass probability estimates | SIGKDD | 2002
[CA2](https://dl.acm.org/doi/10.5555/645530.655658) | Obtaining calibrated probability estimates from decision trees and naive Bayesian classifiers | ICML | 2001
[CA1](https://www.researchgate.net/profile/John-Platt-2/publication/2594015_Probabilistic_Outputs_for_Support_Vector_Machines_and_Comparisons_to_Regularized_Likelihood_Methods/links/004635154cff5262d6000000/Probabilistic-Outputs-for-Support-Vector-Machines-and-Comparisons-to-Regularized-Likelihood-Methods.pdf) | Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods | Advances in large margin classifiers | 1999

**Out-of-Distribution Measurements**
ID | Paper Titles | Venues | Years 
--- | :------ | :---:  | :---:
[D11](https://proceedings.neurips.cc/paper_files/paper/2023/hash/48aaa5ea741ae8430bd58e25917d267d-Abstract-Conference.html) | Understanding contrastive learning via distributionally robust optimization | NeurIPS | 2024
[D10](https://pubsonline.informs.org/doi/10.1287/moor.2022.1275) | Distributionally robust stochastic optimization with Wasserstein distance | Mathematics of Operations Research | 2023
[D9](https://projecteuclid.org/journals/annals-of-statistics/volume-49/issue-3/Learning-models-with-uniform-performance-via-distributionally-robust-optimization/10.1214/20-AOS2004.short) | Learning models with uniform performance via distributionally robust optimization | The Annals of Statistics | 2021
[D8](https://proceedings.neurips.cc/paper/2019/hash/1770ae9e1b6bc9f5fd2841f141557ffb-Abstract.html) | Distributionally robust optimization and generalization in kernel methods | NeurIPS | 2019
[D7](https://www.taylorfrancis.com/books/mono/10.1201/9781420034813/statistical-inference-based-divergence-measures-leandro-pardo) | Statistical inference based on divergence measures | Chapman and Hall/CRC | 2018
[D6](https://www.sciencedirect.com/science/article/abs/pii/S0167637718300506) | Data-driven risk-averse stochastic optimization with Wasserstein metric | Operations Research Letters | 2018
[D5](https://link.springer.com/article/10.1007/s10107-017-1172-1) | Data-driven distributionally robust optimization using the Wasserstein metric: Performance guarantees and tractable reformulations | Mathematical Programming | 2018
[D4](https://pubsonline.informs.org/doi/abs/10.1287/educ.2015.0134) | Data-driven stochastic programming using phi-divergences | The operations research revolution | 2015
[D3](https://pubsonline.informs.org/doi/abs/10.1287/mnsc.1120.1641) | Robust solutions of optimization problems affected by uncertain probabilities | Management Science | 2013 
[D2](https://optimization-online.org/wp-content/uploads/2012/11/3677.pdf) | Kullback-Leibler divergence constrained distributionally robust optimization | | 2013
[D1](https://link.springer.com/article/10.1007/s10107-005-0678-0) | Ambiguous chance constrained problems and robust optimization | Mathematical Programming  | 2006


### UQ on Graph

**Graphical Model**
ID | Paper Titles | Venues | Years 
--- | :------ | :---:  | :---:
[P4](https://epubs.siam.org/doi/abs/10.1137/21M1434453) | Model Uncertainty and Correctability for Directed Graphical Models | JUQ | 2022
[P3](https://epubs.siam.org/doi/abs/10.1137/20M1374614) | Uncertainty Quantification for Markov Random Fields | JUQ | 2021
[P2](https://epubs.siam.org/doi/10.1137/1.9781611974973.17) | The Power of Certainty: A Dirichlet-Multinomial Model for Belief Propagation | ICDM | 2017
[P1](https://link.springer.com/chapter/10.1007/978-3-319-18038-0_49) | SocNL: Bayesian Label Propagation with Confidence | PAKDD | 2015

**GNN**
ID | Paper Titles | Venues | Years 
--- | :------ | :---:  | :---:
[G11](https://www.sciencedirect.com/science/article/abs/pii/S0925231222014424) | A General Framework for Quantifying Aleatoric and Epistemic Uncertainty in Graph Neural Networks | Neurocomputing | 2023
[G10](https://openreview.net/forum?id=rdgB5BqWCw) | Predictive Uncertainty Quantification for Graph Neural Network Driven Relaxed Energy Calculations | NeurIPS Workshop | 2023
[G9](https://arxiv.org/abs/2303.04040) | Uncertainty Quantification of Spatiotemporal Travel Demand with Probabilistic Graph Neural Networks | SIGKDD | 2022
[G8](https://dl.acm.org/doi/abs/10.1145/3534678.3539093) | Uncertainty Quantification of Sparse Travel Demand Prediction with Spatial-Temporal Graph Neural Networks | SIGKDD | 2022
[G7](https://proceedings.neurips.cc/paper_files/paper/2021/hash/95b431e51fc53692913da5263c214162-Abstract.html) | Graph posterior network: Bayesian predictive uncertainty for node classification | NeurIPS | 2021
[G6](https://proceedings.mlr.press/v124/pal20a.html) | Non parametric graph learning for bayesian graph neural networks | UAI | 2020
[G5](https://ojs.aaai.org/index.php/AAAI/article/download/4531/4409) | Bayesian graph convolutional neural networks for semi-supervised classification | AAAI | 2019
[G4](https://arxiv.org/abs/1911.04965) | Bayesian graph convolutional neural networks using node copying | ICML Workshop | 2019
[G3](https://proceedings.mlr.press/v80/pearce18a.html) | High-Quality Prediction Intervals for Deep Learning- A Distribution-Free, Ensembled Approach | ICML | 2018
[G2](https://epubs.siam.org/doi/abs/10.1137/17M1134214) | Uncertainty Quantification in Graph-Based Classification of High Dimensional Data | JUQ | 2018
[G1](https://proceedings.neurips.cc/paper/2018/hash/53f0d7c537d99b3824f0f99d62ea2428-Abstract.html) | Link prediction based on graph neural network | NeurIPS | 2018

**Conformal Prediction for Graphs**
ID | Paper Titles | Venues | Years 
--- | :------ | :---:  | :---:
[CPG4](https://arxiv.org/abs/2305.14535) | Uncertainty Quantification over Graph with Conformalized Graph Neural Networks | NeurIPS | 2023
[CPG3](https://proceedings.mlr.press/v202/h-zargarbashi23a.html) | Conformal Prediction Sets for Graph Neural Networks | ICML | 2023
[CPG2](https://proceedings.mlr.press/v202/clarkson23a.html) | Distribution Free Prediction Sets for Node Classification | ICML | 2023
[CPG1](https://dl.acm.org/doi/abs/10.1145/3534678.3539286) | JuryGCN: Quantifying Jackknife Uncertainty on Graph Convolutional Networks | SIGKDD | 2022

**Calibration for Graphs**
ID | Paper Titles | Venues | Years 
--- | :------ | :---:  | :---:
[CAG10](https://cmsworkshops.com/ICASSP2024/view_paper.php?PaperNum=7277) | On Estimating Link Prediction Uncertainty Using Stochastic Centering | ICASSP | 2024
[CAG9](https://arxiv.org/abs/2401.03350) | Accurate and Scalable Estimation of Epistemic Uncertainty for Graph Neural Networks | ICLR | 2024
[CAG8](https://arxiv.org/abs/2403.04605) | In-n-Out: Calibrating Graph Neural Networks for Link Prediction | arXiv | 2024
[CAG7](https://proceedings.neurips.cc/paper_files/paper/2022/hash/5975754c7650dfee0682e06e1fec0522-Abstract-Conference.html) | What Makes Graph Neural Networks Miscalibrated? | NeurIPS | 2022
[CAG6](https://dl.acm.org/doi/abs/10.1145/3503161.3548423?casa_token=oLE-X0PMypAAAAAA:EcB27ENIY5OkXut9rLe_LocviSKEPoJtxPyS3fmqZ7RG3ayU1CTbvwpbT5XJeLpGmrHqyanUuK7wZg) | GCL: Graph calibration loss for trustworthy graph neural network | MM | 2022
[CAG5](https://ieeexplore.ieee.org/abstract/document/9892866?casa_token=8gacSN0Z8ZgAAAAA:CerSGnfSVX_nsRe4cGLqdUs6_azca6GyO1_TmcVX_cj3owsYYbtUa610H2yzMBqXsNJu6wDuYWCM) | On calibration of graph neural networks for node classification | ICJNN | 2022
[CAG4](https://dl.acm.org/doi/abs/10.1145/3511808.3557556?casa_token=4GVPgq11RzAAAAAA:0R-Cn6wtL5wMwR0Hjzf_SLjjBHaw9RXcHgJfQMTRi5XsXF_raV2er86RL-AagzKEBVl01auGftS3sw) | Calibrate automated graph neural network via hyperparameter uncertainty | CIKM | 2022
[CAG3](https://proceedings.neurips.cc/paper/2021/hash/c7a9f13a6c0940277d46706c7ca32601-Abstract.html) | Be Confident! Towards Trustworthy Graph Neural Networks via Confidence Calibration | NeurIPS | 2021
[CAG2](https://ieeexplore.ieee.org/abstract/document/9679093?casa_token=pNyFkDpFxKYAAAAA:APzIRm9B8tSczE7x-70OtnXxqRX2JL6Av10PM2WvYOYZILgptsE90-hZe1Y-2pXO2cgMo27tq888) | A multi-view confidence-calibrated framework for fair and stable graph representation learning | ICDM | 2021
[CAG1](https://arxiv.org/abs/1905.02296) | Are graph neural networks miscalibrated? | ICML Workshop | 2019

**Out-of-Distribution Measurements for Graphs**
ID | Paper Titles | Venues | Years 
--- | :------ | :---:  | :---:
[DG13](https://dl.acm.org/doi/abs/10.1145/3589334.3645598) | Distributionally Robust Graph-based Recommendation System | WWW | 2024
[DG12](https://ojs.aaai.org/index.php/AAAI/article/view/26239) | Adversarial weight perturbation improves generalization in graph neural networks | AAAI | 2023
[DG11](https://arxiv.org/abs/2306.08210) | Uncertainty-Aware Robust Learning on Noisy Graphs | arXiv | 2023
[DG10](https://ieeexplore.ieee.org/abstract/document/8924766) | Graph adversarial training: Dynamically regularizing based on graph structure | TKDE | 2023
[DG9](https://dl.acm.org/doi/10.1145/3485447.3512172) | Confidence may cheat: Self-training on graph neural networks under distribution shift | WWW | 2022
[DG8](https://arxiv.org/abs/2110.14855) | CAP: Co-Adversarial Perturbation on Weights and Features for Improving Generalization of Graph Neural Networks | arXiv | 2021
[DG7](https://proceedings.mlr.press/v139/yehudai21a.html) | From local structures to size generalization in graph neural networks | ICML | 2021
[DG6](https://arxiv.org/abs/2105.04210) | Robust graph learning under Wasserstein uncertainty | arXiv | 2021
[DG5](https://arxiv.org/abs/2110.10582) | Distributionally robust semi-supervised learning over graphs | arXiv | 2021
[DG4](https://dl.acm.org/doi/abs/10.1145/3394486.3403168) | Gcc: Graph contrastive coding for graph neural network pre-training | SIGKDD | 2020
[DG3](https://proceedings.neurips.cc/paper/2020/hash/3fe230348e9a12c13120749e3f9fa4cd-Abstract.html) | Graph contrastive learning with augmentations | NeurIPS | 2020
[DG2](https://arxiv.org/abs/1905.12265) | Strategies for pre-training graph neural networks | ICLR | 2020
[DG1](http://arxiv.org/abs/2006.04131) | Deep graph contrastive representation learning | ICML Workshop | 2020


## Survey Papers

### UQ on Machine Learning
ID | Paper Titles | Venues | Years 
--- | :------ | :---:  | :---:
[S7](https://www.sciencedirect.com/science/article/abs/pii/S0021999122009652) | Uncertainty quantification in scientific machine learning- Methods, metrics, and comparisons | JCP | 2023
[S6](https://arxiv.org/abs/2007.06823) | Hands-on Bayesian Neural Networks -- A Tutorial for Deep Learning Users | CIM | 2022
[S5](https://arxiv.org/abs/2210.16938) | A view on model misspecification in uncertainty quantification | BNAIC | 2022
[S4](https://www.sciencedirect.com/science/article/pii/S1566253521001081) | A review of uncertainty quantification in deep learning Techniques, applications, and challenges | Information Fusion | 2021
[S3](https://www.hindawi.com/journals/mpe/2020/6068203/) | Basic Framework and Main Methods of Uncertainty Quantification | MPE | 2020
[S2](https://ieeexplore.ieee.org/document/8917207) | Calibrating Uncertainty Models for Steering Angle Estimation | ITSC | 2019
[S1](https://www.sciencedirect.com/science/article/pii/S0888327023007045) | Uncertainty Quantification in Machine Learning for Engineering Design and Health Prognostics: A Tutorial | MSSP | 2015

## Open-Source Code

<table>
    <thead>
        <tr>
            <th>Method</th>
            <th>Model</th>
            <th>Algorithm</th>
            <th>Codelink</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td rowspan=14>Bayesian Method</td>
            <td rowspan=2>General Model</td>
            <td>VAEs</td>
            <td><a href="https://github.com/AntixK/PyTorch-VAE">Link</a></td>
        </tr>
        <tr>
            <td>BNNs</td>
            <td><a href="https://github.com/Harry24k/bayesian-neural-network-pytorch">Link</a></td>
        </tr>
        <tr>
            <td rowspan=12>Graphic Model</td>
            <td>NETCONF</td>
            <td><a href="https://dhivyaeswaran.github.io/code/netconf.zip">Link</a></td>
        </tr>
        <tr>
            <td>GPN</td>
            <td><a href="https://www.daml.in.tum.de/graph-postnet">Link</a></td>
        </tr>
        <tr>
          <td>VGAE</td>
          <td><a href="https://github.com/tkipf/gae">Link</a></td>
        </tr>
        <tr>
            <td>DGVAE</td>
            <td><a href="https://github.com/xiyou3368/DGVAE">Link</a></td>
        </tr>
        <tr>
            <td>SIG-VAE</td>
            <td><a href="https://github.com/sigvae/SIGraphVAE">Link</a></td>
        </tr>
        <tr>
            <td>VGNAE</td>
            <td><a href="https://github.com/SeongJinAhn/VGNAE">Link</a></td>
        </tr>
        <tr>
            <td>Graphite</td>
            <td><a href="https://github.com/ermongroup/graphite">Link</a></td>
        </tr>
        <tr>
            <td>VGRNN</td>
            <td><a href="https://github.com/VGraphRNN/VGRNN">Link</a></td>
        </tr>
        <tr>
            <td>Bayesian GCNN</td>
            <td><a href="https://github.com/huawei-noah/BGCN">Link</a></td>
        </tr>
        <tr>
            <td>Bayesian GCNN (node copying)</td>
            <td><a href="https://github.com/floregol/BGCN_copying">Link</a></td>
        </tr>
        <tr>
            <td>S-BGCN-T-K</td>
            <td><a href="https://github.com/zxj32/uncertainty-GNN">Link</a></td>
        </tr>
        <tr>
            <td>VGCN</td>
            <td><a href="https://github.com/ebonilla/VGCN">Link</a></td>
        </tr>
        <tr>
            <td rowspan=13>Conformal Prediction</td>
            <td rowspan=9>General Model</td>
            <td>CPCS</td>
            <td><a href="https://github.com/ryantibs/conformal/tree/master/tibshirani2019">Link</a></td>
        </tr>
        <tr>
            <td>CQR</td>
            <td><a href="https://github.com/yromano/cqr">Link</a></td>
        </tr>
        <tr>
            <td>APS</td>
            <td><a href="https://github.com/msesia/arc">Link</a></td>
        </tr>
        <tr>
            <td>conformalbayes</td>
            <td><a href="https://github.com/CoryMcCartan/conformalbayes">Link</a></td>
        </tr>
        <tr>
            <td>EnbPI</td>
            <td><a href="https://github.com/hamrel-cxu/EnbPI">Link</a></td>
        </tr>
        <tr>
            <td>CP with Missing Values</td>
            <td><a href="https://github.com/mzaffran/ConformalPredictionMissingValues">Link</a></td>
        </tr>
        <tr>
            <td>LCP</td>
            <td><a href="https://github.com/LeyingGuan/LCP">Link</a></td>
        </tr>
        <tr>
            <td>stabCP</td>
            <td><a href="https://github.com/EugeneNdiaye/stable_conformal_prediction">Link</a></td>
        </tr>
        <tr>
            <td>OQR</td>
            <td><a href="https://github.com/Shai128/oqr">Link</a></td>
        </tr>
        <tr>
            <td rowspan=4>Graphic Model</td>
            <td>NAPS</td>
            <td><a href="https://github.com/jase-clarkson/graph_cp">Link</a></td>
        </tr>
        <tr>
            <td>DAPS</td>
            <td><a href="https://github.com/soroushzargar/DAPS">Link</a></td>
        </tr>
        <tr>
            <td>CF-GNN</td>
            <td><a href="https://github.com/snap-stanford/conformalized-gnn">Link</a></td>
        </tr>
        <tr>
            <td>JuryGCN</td>
            <td><a href="https://github.com/BlueWhaleZhou/JuryGCN_UQ">Link</a></td>
        </tr>
        <tr>
            <td rowspan=10>Calibration</td>
            <td rowspan=5>General Model</td>
            <td>Dirichlet Calibration</td>
            <td><a href="https://github.com/dirichletcal/dirichletcal.github.io">Link</a></td>
        </tr>
        <tr>
            <td>Calibrated Regression</td>
            <td><a href="https://github.com/AnthonyRentsch/calibrated_regression?tab=readme-ov-file">Link</a></td>
        </tr>
        <tr>
            <td>Focal Calibration</td>
            <td><a href="https://github.com/torrvision/focal_calibration">Link</a></td>
        </tr>
        <tr>
            <td>Label Smoothing</td>
            <td><a href="https://github.com/seominseok0429/label-smoothing-visualization-pytorch">Link</a></td>
        </tr>
        <tr>
            <td>Spline Calibration</td>
            <td><a href="https://github.com/kartikgupta-at-anu/spline-calibration">Link</a></td>
        </tr>
        <tr>
            <td rowspan=5>Graphic Model</td>
            <td>G-&Delta;UQ</td>
            <td><a href="https://github.com/pujacomputes/gduq">Link</a></td>
        </tr>
        <tr>
            <td>CaGCN</td>
            <td><a href="https://github.com/BUPT-GAMMA/CaGCN">Link</a></td>
        </tr>
        <tr>
            <td>GATS</td>
            <td><a href="https://github.com/hans66hsu/GATS">Link</a></td>
        </tr>
        <tr>
            <td>RBS</td>
            <td><a href="https://github.com/liu-yushan/calGNN">Link</a></td>
        </tr>
        <tr>
            <td>HyperU-GCN</td>
            <td><a href="https://github.com/xyang2316/HyperU-GCN">Link</a></td>
        </tr>
    </tbody>
</table>

## Tutorial
| Tutorial | Graphic Model | Bayes | CP | Cal | OOD | Others | Venues | Year |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| [Graph Learning: Principles, Challenges, and Open Directions](https://icml.cc/virtual/2024/tutorial/35233) | :heavy_check_mark: |  |  |  |  |  | ICML | 2024 |
| [Formalizing Robustness in Neural Networks: Explainability, Uncertainty, and Intervenability](https://alregib.ece.gatech.edu/aaai-2024-tutorial/) |  |  |  |  | :heavy_check_mark: |  | AAAI | 2024 |
| [Distribution-Free Predictive Uncertainty Quantification: Strengths and Limits of Conformal Prediction](https://icml.cc/virtual/2024/tutorial/35231) |  |  | :heavy_check_mark: |  |  |  | ICML | 2024 |
| [Distribution-Free Predictive Uncertainty Quantification: Strengths and Limits of Conformal Prediction ](/) |  |  | :heavy_check_mark: |  |  |  | UAI | 2024 |
| [Graph Neural Networks: Foundation, Frontiers and Applications](https://graph-neural-networks.github.io/tutorial_kdd23.html) | :heavy_check_mark: |  |  |  |  |  | KDD | 2023 |
| [Large-Scale Graph Neural Networks: The Past and New Frontiers](https://dl.acm.org/doi/10.1145/3580305.3599565) | :heavy_check_mark: |  |  |  |  |  | KDD | 2023 |
| [Hyperbolic Graph Neural Networks: A Tutorial on Methods and Applications](https://dl.acm.org/doi/10.1145/3580305.3599562) | :heavy_check_mark: |  |  |  |  |  | KDD | 2023 |
| [Fairness in Graph Machine Learning: Recent Advances and Future Prospectives](https://dl.acm.org/doi/10.1145/3580305.3599555) | :heavy_check_mark: |  |  |  |  |  | KDD | 2023 |
| [Graph Neural Networks: Foundation, Frontiers and Applications](https://graph-neural-networks.github.io/tutorial_aaai23.html) | :heavy_check_mark: |  |  |  |  |  | AAAI | 2023 |
| [Temporal Graph Mining for Fraud Detection](https://mtcazzolato.github.io/tutorial-icdm23/) | :heavy_check_mark: |  |  |  |  |  | ICDM | 2023 |
| [Recent Advances in Bayesian Optimization](https://bayesopt-tutorial.github.io/) |  | :heavy_check_mark: |  |  |  |  | AAAI | 2023 |
| [Uncertainty Quantification in Deep Learning](https://lingkai-kong.com/kdd23_tutorial/) |  | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark: |  |  | KDD | 2023 |
| [Modeling and Exploiting Data Heterogeneity under Distribution Shifts](https://neurips.cc/virtual/2023/tutorial/73953) |  |  |  |  | :heavy_check_mark: |  | NeurIPS | 2023 |
| [Trustworthy Graph Learning: Reliability, Explainability, and Privacy Protection](https://ai.tencent.com/ailab/ml/twgl/) | :heavy_check_mark: |  |  |  |  |  | KDD | 2022 |
| [Algorithmic Fairness on Graphs: Methods and Trends](https://dl.acm.org/doi/abs/10.1145/3534678.3542599) | :heavy_check_mark: |  |  |  |  |  | KDD | 2022 |
| [Automated Learning from Graph-Structured Data](https://quanmingyao.github.io/AutoML.github.io/aaai22-tutorial.html) | :heavy_check_mark: |  |  |  |  |  | AAAI | 2022 |
| [Fairness in Graph Mining: Metrics, Algorithms, and Applications](https://yushundong.github.io/ICDM_2022_tutorial.html) | :heavy_check_mark: |  |  |  |  |  | ICDM | 2022 |
| [Advances in Bayesian Optimization](https://neurips.cc/virtual/2022/tutorial/55806) |  | :heavy_check_mark: |  |  |  |  | NeurIPS | 2022 |
| [Bayesian Optimization: From Foundations to Advanced Topics](https://bayesopt-tutorial.github.io/syllabus/combined.pdf) |  | :heavy_check_mark: |  |  |  |  | AAAI | 2022 |
| [Sampling as First-Order Optimization over a space of probability measures ](https://icml.cc/virtual/2022/tutorial/18437) |  |  |  |  |  |  | ICML | 2022 |
| [Probabilistic Circuits: Representations, Inference, Learning and Applications](https://neurips.cc/virtual/2022/tutorial/55809) |  |  |  |  |  | :heavy_check_mark: | NeurIPS | 2022 |
| [Graph Representation Learning: Foundations, Methods, Applications and Systems](https://kdd2021graph.github.io/) | :heavy_check_mark: |  |  |  |  |  | KDD | 2021 |
| [Toward Explainable Deep Anomaly Detection](https://dl.acm.org/doi/10.1145/3447548.3470794) |  |  |  |  | :heavy_check_mark: |  | KDD | 2021 |
| [The Art of Gaussian Processes: Classical and Contemporary](https://neurips.cc/virtual/2021/tutorial/21890) |  | :heavy_check_mark: |  |  |  |  | NeurIPS | 2021 |
| [On Calibration and Out-of-Domain Generalization](https://iclr.cc/virtual/2021/3912) |  |  |  | :heavy_check_mark: | :heavy_check_mark: |  | ICLR | 2021 |
| [Deep Graph Learning: Foundations, Advances and Applications](https://ai.tencent.com/ailab/ml/KDD-Deep-Graph-Learning.html) | :heavy_check_mark: |  |  |  |  |  | KDD | 2020 |
| [Differential Deep Learning on Graphs and its Applications](http://www.calvinzang.com/DDLG_AAAI_2020.html) | :heavy_check_mark: |  |  |  |  |  | AAAI | 2020 |
| [Bayesian Deep Learning and a Probabilistic Perspective of Model Construction](https://icml.cc/virtual/2020/tutorial/5750) |  | :heavy_check_mark: |  |  |  |  | ICML | 2020 |
| [Robust Deep Learning Methods for Anomaly Detection](https://raghavchalapathy.github.io/KDD-Tutorials-2020-Deep-Robust-Anomaly-Detection/) |  |  |  |  | :heavy_check_mark: |  | KDD | 2020 |
| [How to calibrate your neural network classifier: Getting true probabilities from a classification model](https://github.com/nplan-io/kdd2020-calibration) |  |  |  | :heavy_check_mark: |  |  | KDD | 2020 |
| [Advances in Approximate Inference](https://neurips.cc/virtual/2020/tutorial/16651) |  |  |  |  |  | :heavy_check_mark: | NeurIPS | 2020 |
| [Practical Uncertainty Estimation and Out-of-Distribution Robustness in Deep Learning](https://neurips.cc/virtual/2020/tutorial/16649) |  |  |  |  | :heavy_check_mark: |  | NeurIPS | 2020 |
| [Graph Representation Learning](https://www.cs.mcgill.ca/~wlh/grl_book/) | :heavy_check_mark: |  |  |  |  |  | AAAI | 2019 |
| [Representation Learning on Graphs and Manifolds](https://iclr.cc/virtual/2019/workshop/631) | :heavy_check_mark: |  |  |  |  |  | ICLR | 2019 |
| [A Primer on PAC-Bayesian Learning](https://icml.cc/virtual/2019/tutorial/4338) |  | :heavy_check_mark: |  |  |  |  | ICML | 2019 |
| [Deep Learning with Bayesian Principles](https://neurips.cc/virtual/2019/tutorial/13205) |  | :heavy_check_mark: |  |  |  |  | NeurIPS | 2019 |
| [Deep Bayesian Mining, Learning and Understanding](https://dl.acm.org/doi/10.1145/3292500.3332267) |  | :heavy_check_mark: |  |  |  |  | KDD | 2019 |
| [Deep Bayesian and Sequential Learning](http://chien.cm.nctu.edu.tw/home/aaai-tutorial/) |  | :heavy_check_mark: |  |  |  |  | AAAI | 2019 |
| [Knowledge-based Sequential Decision-Making under Uncertainty](http://www.cs.binghamton.edu/~szhang/2019_aaai_tutorial/) |  |  |  |  |  | :heavy_check_mark: | AAAI | 2019 |
| [Tractable Probabilistic Models: Representations, Algorithms, Learning, and Applications](https://web.cs.ucla.edu/~guyvdb/slides/TPMTutorialUAI19.pdf) |  |  |  |  |  | :heavy_check_mark: | UAI | 2019 |
| [Variational Bayes and Beyond: Bayesian Inference for Big Data](https://icml.cc/virtual/2018/tutorial/1858) |  | :heavy_check_mark: |  |  |  |  | ICML | 2018 |
| [Scalable Bayesian Inference](https://neurips.cc/virtual/2018/tutorial/10984) |  | :heavy_check_mark: |  |  |  |  | NeurIPS | 2018 |
| [Bayesian Incremental Learning for Deep Neural Networks](https://iclr.cc/virtual/2018/workshop/474) |  | :heavy_check_mark: |  |  |  |  | ICLR | 2018 |
| [Bayesian Approaches for Blackbox Optimization](https://www.microsoft.com/en-us/research/video/bayesian-approaches-for-black-box-optimization/) |  | :heavy_check_mark: |  |  |  |  | UAI | 2018 |
| [Uncertainty Estimation via Stochastic Batch Normalization](https://iclr.cc/virtual/2018/workshop/458) |  |  |  |  |  | :heavy_check_mark: | ICLR | 2018 |
| [Deep Probabilistic Modelling with Gaussian Processes](https://neurips.cc/virtual/2017/tutorial/8731) |  | :heavy_check_mark: |  |  |  |  | NeurIPS | 2017 |
| [Statistical Relational Artificial Intelligence: Logic, Probability and Computation](https://neurips.cc/virtual/2017/tutorial/8739) |  |  |  |  |  | :heavy_check_mark: | NeurIPS | 2017 |
| [Non-IID Learning](https://www.researchgate.net/publication/321049891_Non-IID_Learning) |  |  |  |  | :heavy_check_mark: |  | KDD | 2017 |
| [Reasoning Under Uncertainty with Subjective Logic](https://www.auai.org/uai2016/tutorials_pres/subj_logic.pdf) |  |  |  |  |  | :heavy_check_mark: | UAI | 2016 |
| [Bayesian Time Series Modeling: Structured Representations for Scalability](https://icml.cc/2015/index.html%3Fp=97.html) |  | :heavy_check_mark: |  |  |  |  | ICML | 2015 |
| [Optimal Algorithms for Learning Bayesian Network Structures](https://www.auai.org/uai2015/proceedings/slides/UAI2015_LearningBN_PartI.pdf) |  | :heavy_check_mark: |  |  |  |  | UAI | 2015 |
| [Computational Complexity of Bayesian Networks](https://www.auai.org/uai2015/proceedings/slides/UAI2015_Comp_LN.pdf) |  | :heavy_check_mark: |  |  |  |  | UAI | 2015 |
| [Probabilistic Programming](https://neurips.cc/virtual/2015/tutorial/4892) |  |  |  |  |  | :heavy_check_mark: | NeurIPS | 2015 |
| [Bayesian Posterior Inference in the Big Data Arena: An introduction to probabilistic programming](https://icml.cc/2014/index/article/17.htm)|  | :heavy_check_mark: |  |  |  |  |ICML | 2014|
| [Approximate Bayesian Computation (ABC)](https://neurips.cc/virtual/2013/tutorial/3686)|  | :heavy_check_mark: |  |  |  |  | NeurIPS | 2013|
| [Exact Approximate Learning](https://neurips.cc/virtual/2012/tutorial/3133)||  |  |  |  | :heavy_check_mark: | NeurIPS | 2012|
| [Linear Programming Relaxations for Graphical Models](https://neurips.cc/virtual/2011/tutorial/2509)|:heavy_check_mark: |  |  |  |  |  | NeurIPS | 2011|
| [Modern Bayesian Nonparametrics](https://neurips.cc/virtual/2011/tutorial/2506)|| :heavy_check_mark: |  |  |  |  | NeurIPS | 2011|
