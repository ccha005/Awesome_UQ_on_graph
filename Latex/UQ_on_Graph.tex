\section{Uncertainty Quantification on Graphs}
In the field of graph learning, Probabilistic Graphical Models (PGM) and Graph Neural Networks (GNNs) are two predominant methods for processing graph data. 
This section focuses on exploring various Uncertainty Quantification (UQ) techniques that are specifically designed to measure and quantify the predictive uncertainties of these models. 
In this realm, the targets of UQ can vary widely, including but not limited to node or graph classification predictions, and quantities of interest (QoIs) relevant to specific learning tasks. 

\subsection{Bayesian Approaches}

Bayesian Approaches in Uncertainty Quantification for graph learning employ probabilistic modeling to effectively handle uncertainty. Central to these methods is Bayesian inference, updating predictions with new information and integrating uncertainty into model parameters. This technique represents parameters as probability distributions, allowing for a detailed evaluation of uncertainty. It addresses both aleatoric (data-related) and epistemic (model-related) uncertainties, providing a robust framework for graph learning scenarios.


%\subsection{Uncertainty Quantification in Probabilitic Graphical Models}

%Applying PGMs to graph data involves probabilistic reasoning and learning on graph-structured data. 
%In this context, nodes and edges in the graph represent random variables and the probabilistic relationships between these variables, respectively. 
%This probabilistic modeling of the graph enables the use of PGM-specific inference and learning algorithms for various tasks like node classification, link prediction, and more. 
%Simultaneously, the UQ methods for PGMs can naturally provide uncertainty estimates for predictions related to these graph learning tasks. 

%\subsubsection{UQ of Marginal Probabilities for Variable Node} 

%\subsubsection{UQ of QoIs}
%\subsection{Uncertainty Quantification in Graph Neural Networks}
