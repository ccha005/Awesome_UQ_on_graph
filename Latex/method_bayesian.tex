% \section{Methods for Handling Uncertainty}
\subsection{Bayesian Methods}
\subsubsection{Bayesian Methods Overview}\hfill\\
In the realm of UQ, Bayesian methods stand as a pivotal approach, offering a powerful framework for dealing with uncertainty in complex systems. 
At the heart of Bayesian UQ is the application of Bayes' Theorem, which mathematically expresses how our belief or knowledge about a certain parameter or model is updated with evidence. 
The theorem is elegantly encapsulated in the formula: 
\begin{equation}
    \label{eq:Bayes_Theorem}
    P(\boldsymbol{\theta}|D)=\frac{P(D|\boldsymbol{\theta})P(\boldsymbol{\theta})}{P(D)},
\end{equation}
%P(θ|D) = [P(D|θ)P(θ)] / P(D), 
where $P(\boldsymbol{\theta}|D)$ is the posterior probability of the parameter $\boldsymbol{\theta}$ given the data $D=\{X,Y\}$, $P(D|\boldsymbol{\theta})$ is the likelihood of observing the data given the parameter, $P(\boldsymbol{\theta})$ is the prior probability of the parameter, and $P(D)$ is the marginal likelihood of the data. 
This Bayesian paradigm shifts the focus from a single 'true' model to a probabilistic distribution of models, reflecting all possible values that the parameters can take, weighted by their likelihood. 
By incorporating prior knowledge and continuously updating it with new data, Bayesian methods provide a dynamic and adaptive approach to UQ, allowing for a more comprehensive understanding of uncertainty in models.

Advancing from the foundational Bayesian principles, Bayesian Neural Networks (BNNs) offer an intricate method that integrates the flexibility of neural networks with the probabilistic rigor of Bayesian inference. 
BNNs are predicated on the notion of assigning probability distributions to the neural network's parameters $\boldsymbol{\theta}$, which encapsulates the model's uncertainty. 
This is a departure from traditional neural networks that often yield a single point estimate for parameters upon training completion.
During the training phase, BNNs aim to ascertain the posterior distribution of the parameters $P(\boldsymbol{\theta}|D)$. 
This is a result of updating the prior distribution $P(\boldsymbol{\theta})$ with the likelihood of the observed data $P(D|\boldsymbol{\theta})$, as Eq. (\ref{eq:Bayes_Theorem}).
In the context of predictions, BNNs leverage Bayesian model averaging during the test phase. 
This is not merely based on a singular set of parameters but rather an aggregation of multiple parameter sets sampled from the posterior distribution. 
For a given test sample $\mathbf{x}^*$, the prediction thereby incorporates the model uncertainty, yielding the predictive distribution:
\begin{equation}
    \label{eq:Bayes_prediction}
    p(y^* | \mathbf{x}^*, D) = \int p(y^* | \mathbf{x}^*, \boldsymbol{\theta}) p(\boldsymbol{\theta} | D) d\boldsymbol{\theta}.
\end{equation}

Due to the general intractability of the integral, various techniques for inferring $p(\boldsymbol{\theta} | D)$ have been proposed. 
Gal et al. \cite{gal2016dropout} demonstrated that Monte Carlo dropout is equivalent to sampling from an approximate posterior of $\boldsymbol{\theta}$, allowing Eq. (\ref{eq:Bayes_prediction}) to be simplified to the following Monte Carlo integral:
\begin{equation}
    \label{eq:Bayes_MC_dropout}
    p(y^* | \mathbf{x}^*, D) \approx \frac{1}{S} \sum^{S}_{i=1} p(y^* | \mathbf{x}^*, \boldsymbol{\theta}_i),
\end{equation}
where dropout is used to obtain $S$ weights $\boldsymbol{\theta}_i$. 
Hasanzadeh et al. \cite{hasanzadeh2020bayesian} extended the concept of dropout to graphs, introducing Graph DropConnect (GDC) to more effectively leverage the topological structure of graphs. 
Another technique for approximating the posterior distribution p(\boldsymbol{\theta} | D) is variational inference (VI). 
The objective is to approximate a distribution $q_{\phi}(\boldsymbol{\theta}) $ that is close to the posterior $p(\boldsymbol{\theta} | D)$. 
This can be achieved by minimizing the Kullback-Leibler divergence $\text{KL}(q_{\phi}(\boldsymbol{\theta}) \| p(\boldsymbol{\theta} | D))$, and in practice, by maximizing the following evidence lower bound (ELBO) \cite{blei2017variational}:
\begin{equation}
    \label{Bayesian_VI_ELBO}
    \mathcal{L}_{\text{ELBO}}(\phi)=\int q_{\phi}(\boldsymbol{\theta}) \log p(Y | X, \boldsymbol{\theta}) d\boldsymbol{\theta} - \text{KL}(q_{\phi}(\boldsymbol{\theta}) \| p(\boldsymbol{\theta})))
\end{equation}

Once $P(\boldsymbol{\theta}|D)$ is obtained, the uncertainty quantified by the above Bayesian framework can be elegantly decomposed by the following relationship:\cite{depeweg2018decomposition}:
\begin{equation}
\label{eq:Bayes_AU_EU_decomp}
    \underbrace{I(y^*, \boldsymbol{\theta} | \mathbf{x}^*, D)}_{Epistemic} = \underbrace{\mathcal{H}\left[ \mathbb{E}_{P(\boldsymbol{\theta}|D)}\left[P(y^*|\mathbf{x}^*, \boldsymbol{\theta})\right]\right]}_{Entropy} - \underbrace{\mathbb{E}_{P(\boldsymbol{\theta}|D)}\left[\mathcal{H}\left[P(y^*|\mathbf{x}^*, \boldsymbol{\theta})\right]\right]}_{Aleatoric},
\end{equation}
where $\mathcal{H}(\cdot)$ is Shannon’s entropy of a probability distribution.
The \textit{entropy} term represents the total uncertainty in the prediction while the \textit{aleatoric} term reflects the inherent noise in the data that cannot be reduced with more information. 
The subtraction of aleatoric uncertainty from total uncertainty provides the measure of epistemic uncertainty, which denotes the uncertainty in the model's parameters and reduces as more data becomes available. 
This mathematical demarcation between the uncertainties empowers BNNs to provide a nuanced understanding of prediction reliability and decision-making under uncertainty.

\subsubsection{Bayesian Methods for Graphs}\hfill\\
Bayesian methods for semi-supervised node classification on graphs focus on obtaining the posterior probability distribution of nodes. One route lies in assigning a prior probability distribution to each node, then updating it with evidence propagated from other nodes to obtain the posterior distribution. Yamaguchi et al. \cite{yamaguchi2015socnl} assumed the label is a categorical random variable as $P(\hat{y}_i=k|\boldsymbol{\theta})$, where $\boldsymbol{\theta}$
 is the parameter of the categorical distribution. 
 Based on the smoothness hypothesis, they believed that a neighbor of node $i$ shares the same parameter $\boldsymbol{\theta}$ as $i$. 
 This leads to the multinomial likelihood function of labels of neighbors of $i$ $P(\hat{N}_i|\boldsymbol{\theta})\propto\Pi_{k=1}^K\theta_k^{n_{ik}}$ and the conjugate Dirichlet prior $P(\boldsymbol{\theta})\propto\Pi_{k=1}^K\theta_k^{\alpha_k-1}$
 , where $n_{ik}$ is the number of i’s neighbors whose label is $k$, and $\boldsymbol{\alpha}=(\alpha_1,\alpha_2,\cdots,\alpha_K)^T$ is the parameter of Dirichlet distribution. 
 Combining these, the posterior distribution of $\boldsymbol{\theta}$ is $P(\boldsymbol{\theta}|\hat{N}_i)\propto\Pi_{k=1}^K\theta_k^{\alpha_k+n_{ik}-1}$. Beyond the smoothness hypothesis and label propagation, Eswaran et al. \cite{eswaran2017power} used compatibility matrices to represent the strength of connections between nodes and propagates multinomial messages to support both homophily and heterophily network effects. 
 To handle high-dimensional features of nodes, Stadler et al. \cite{stadler2021graph} employed MLP encoding and computes node-level pseudo-counts, then propagates them via PPR-based message passing. All three methods utilize Dirichlet priors and posteriors, with the main difference being in the form of multinomial distribution evidence propagated.

Another route lies in transferring general Bayesian neural networks to GNNs. These works consider model parameters, passed messages, etc., as distributions rather than fixed values, and propose a series of Bayesian Graph Neural Networks (BGNNs).
To address limitations in GCNs' ability to handle uncertain graph structures, Zhang et al. \cite{zhang2019bayesian} treated the observed graph $G_{obs}$ as a sample from a random graph family. As a result, the posterior probability of node (or graph) labels can be computed by:
\begin{equation}
    \label{eq: BGCN_random_graph_post}
    p(\mathbf{Z}|\mathbf{Y}_{\mathcal{L}}, \mathbf{X}, G_{obs})=\int p(\mathbf{Z}|\boldsymbol{\theta}, G, \mathbf{X})p(\boldsymbol{\theta}|\mathbf{Y}_{\mathcal{L}}, G, \mathbf{X})p(G|\lambda)p(\lambda|G_{obs})\,d\boldsymbol{\theta}\,dG \,d\lambda\,.
\end{equation}
Here $\boldsymbol{\theta}$ is a random variable representing the parameters of a Bayesian GCN over graph $G$, and $\lambda$ denotes the parameters that characterize a family of random graphs. 
$\mathbf{Y}_{\mathcal{L}}$ and $\mathbf{X}$ represent the training label set and the node feature matrix, respectively.
$p(\mathbf{Z}|\boldsymbol{\theta}, G, \mathbf{X})$ can be modelled using a categorical distribution by applying a softmax function to the output of the $L$-layer GCN $\mathbf{Z}=\mathbf{H}^{(L)}$. 
Due to the intractability of the integral in Eq. (\ref{eq: BGCN_random_graph_post}), the authors employ the following Monte Carlo approximation:
\begin{equation}
    \label{eq: BGCN_random_graph_post_MC}
    p(\mathbf{Z}|\mathbf{Y}_{\mathcal{L}}, \mathbf{X}, G_{obs}) \approx \frac{1}{N_{G}S}\sum_{i=1}^{N_G}\sum_{s=1}^{S} p(\mathbf{Z}|\boldsymbol{\theta}_{s,i}, G_i, \mathbf{X})\,.
\end{equation}
In this approximation, $N_G$ graphs $G_i$ are sampled from $p(G|\hat{\lambda})$, where $\hat{\lambda}$ is the parameter of the random graph model obtained through maximum a posteriori estimation $\hat{\lambda}=\arg\max_{\lambda}p(\lambda|G_{obs})$. 
$S$ weights $\boldsymbol{\theta}$ are drawn from $p(\boldsymbol{\theta}|\mathbf{Y}_{\mathcal{L}}, G_i, \mathbf{X})$ using Monte Carlo dropout across the Bayesian GCN corresponding to $G_i$.

Regarding the specific choice of the random graph model in  Eq. (\ref{eq: BGCN_random_graph_post}), Zhang et al. \cite{zhang2019bayesian} utilized an assortative mixed membership stochastic block model (a-MMSBM) \cite{li2016scalable,gopalan2012scalable}. 
To more effectively harness the information offered by node features and training labels for the inference of graph topology, Pal et al. \cite{pal2019bayesian} introduced a generative model based on node copying as an alternative to the a-MMSBM. 
Motivated by comparable considerations, Pal et al. \cite{pal2020non} proposed a non-parametric posterior distribution of the graph $G$ to infer the graph topology.

In addition to considering the observed graph as sampled from a random graph family, some studies also treat the inputs and other elements within the GNN as random variables.
To model the propagation of uncertainty in message-passing mechanisms, Xu et al. \cite{xu2022uncertainty} treated messages as multivariate Gaussian variables and employed GNNs to predict their means. To align with the intuition that more neighboring nodes provide more evidence, they defined an uncertainty propagation mechanism in GNNs for predicting the covariance of Gaussian distributions, which differs from traditional message passing. The covariance ultimately provides the uncertainty of predictions. 
Zhao et al. \cite{zhao2020uncertainty} viewed model parameters as variables and then obtained both epistemic uncertainty and aleatoric uncertainty based on Eq. (\ref{eq:Bayes_AU_EU_decomp}). 
Additionally, this work incorporates uncertainty from evidence theory, namely \textit{vacuity} due to lack of evidence and \textit{dissonance} due to conflicting evidence, offering a richer representation of uncertainty. 
Elinas et al. \cite{elinas2020variational}considered the adjacency matrix $\mathbf{A}$ as a random variable. 
The prior distribution of the adjacency matrix $\mathbf{A}$ is given by:
\begin{equation}
    \label{Elinas_prior_A}
    p(\mathbf{A})=\Pi_{ij}p(A_{ij}),\,
    \text{with}\,p(A_{ij})=\text{Bern}(A_{ij}|\rho_{ij}^o), 
\end{equation}
where $\text{Bern}(A_{ij}|\rho_{ij}^o)$ is a Bernoulli distribution over $\rho_{ij}^o$. 
The variational posterior, which takes a form similar to the prior, is given by:
\begin{equation}
    \label{Elinas_var_post_A}
    q_{\phi}(\mathbf{A})=\Pi_{ij}q_{\phi}(A_{ij}),\,
    \text{with}\,q_{\phi}(A_{ij})=\text{Bern}(A_{ij}|\rho_{ij}),\, \rho_{ij}>0, 
\end{equation}
where $\rho_{ij}$ are free parameters then $\phi = \{\rho_{ij}\}$. 
By relaxing the discrete distribution to a continuous Concrete distribution \cite{jang2016categorical,maddison2016concrete} and maximizing the ELBO, they are able to estimate the parameters $\phi$ of the posterior $q_{\phi}(\mathbf{A})$. 
Munikoti et al. \cite{munikoti2023general} considered probabilistic links, noise in node features, and modeling errors, treating node features, links between nodes, and model parameters as variables. They propagated aleatoric uncertainty to the output by defining mechanisms for the propagation of means and variances of the node embeddings in GNN, while also estimating epistemic uncertainty through MC dropout. 
 %Another route lies in transferring general Bayesian neural networks to GNNs. These works consider model parameters, passed messages, etc., as distributions rather than fixed values, and propose a series of Bayesian Graph Neural Networks (BGNNs).
 %Munikoti et al. \cite{munikoti2023general} proposed a Bayesian graph neural network framework for quantifying aleatoric and epistemic uncertainties. They derived the relationship between the mean and variance of neurons in one layer of the GNN with the previous layer to propagate aleatoric uncertainty to the model output, and obtained epistemic uncertainty through Monte Carlo dropout.

%In the field of graph learning, Probabilistic Graphical Models (PGM) and Graph Neural Networks (GNNs) are two predominant methods for processing graph data. 
%This section focuses on exploring various Uncertainty Quantification (UQ) techniques that are specifically designed to measure and quantify the predictive uncertainties of these models. 
%In this realm, the targets of UQ can vary widely, including but not limited to node or graph classification predictions, and quantities of interest (QoIs) relevant to specific learning tasks. 
%\subsection{Uncertainty Quantification in Probabilistic Graphical Models}

%Applying PGMs to graph data involves probabilistic reasoning and learning on graph-structured data. 
%In this context, nodes and edges in the graph represent random variables and the probabilistic relationships between these variables, respectively. 
%This probabilistic modeling of the graph enables the use of PGM-specific inference and learning algorithms for various tasks like node classification, link prediction, and more. 
%Simultaneously, the UQ methods for PGMs can naturally provide uncertainty estimates for predictions related to these graph learning tasks. 

%\subsubsection{UQ of Marginal Probabilities for Variable Node} 

%\subsubsection{UQ of QoIs}
%\subsection{Uncertainty Quantification in Graph Neural Networks}
